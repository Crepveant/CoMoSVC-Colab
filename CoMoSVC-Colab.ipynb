{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoMoSVC: Consistency Model Based Singing Voice Conversion (Colab)\n",
    "\n",
    "This notebook provides a complete workflow to set up, prepare data, train, and run inference for the **CoMoSVC** project.\n",
    "\n",
    "**This version has been modified to integrate with Google Drive for datasets, checkpoints, and results, ensuring your work is saved across sessions.**\n",
    "\n",
    "**Links:**\n",
    "- **Adapted Colab Repository:** [https://github.com/Crepveant/CoMoSVC-Colab](https://github.com/Crepveant/CoMoSVC-Colab)\n",
    "- **Original Research Paper:** [https://arxiv.org/pdf/2401.01792.pdf](https://arxiv.org/pdf/2401.01792.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, we'll connect to Google Drive, clone the repository, and install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cloning the repository...\")\n",
    "!git clone https://github.com/Crepveant/CoMoSVC-Colab.git\n",
    "%cd CoMoSVC-Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing dependencies from requirements.txt...\")\n",
    "!pip install -r requirements.txt\n",
    "print(\"\\n‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. Download Pre-trained Components\n",
    "\n",
    "Next, we'll download the essential pre-trained models: the vocoder, content encoder, and pitch extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading and extracting the HiFiGAN Vocoder (m4singer_hifigan)...\")\n",
    "!gdown --id 10LD3sq_zmAibl379yTW5M-LXy2l_xk6h\n",
    "!unzip -q m4singer_hifigan.zip\n",
    "\n",
    "print(\"\\nDownloading the Content Encoder (ContentVec)...\")\n",
    "!mkdir -p Content\n",
    "!gdown --id 1A2RQQY7gSEbdfiTHdOcNIjpnNNDYZM0b -O Content/checkpoint_best_legacy_500.pt\n",
    "\n",
    "print(\"\\nDownloading and extracting the Pitch Extractor (m4singer_pe)...\")\n",
    "!gdown --id 19QtXNeqUjY3AjvVycEt3G83lXn2HwbaJ\n",
    "!unzip -q m4singer_pe.zip\n",
    "\n",
    "print(\"\\n‚úÖ All components downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Dataset and Workspace Preparation\n",
    "\n",
    "Instead of uploading files, we will link directories in this Colab session to your Google Drive. This is the key step to make your work persistent.\n",
    "\n",
    "### ‚ö†Ô∏è **Action Required Before Running the Next Cell**\n",
    "\n",
    "1.  Open your Google Drive.\n",
    "2.  Create a main folder for your dataset. For example, create a folder named `CoMoSVC_Dataset`.\n",
    "3.  Inside that folder, create sub-folders for each singer (e.g., `my_singer`).\n",
    "4.  Upload your audio files into the respective singer folders.\n",
    "5.  In the form below, enter the path to the main folder you created (e.g., `CoMoSVC_Dataset`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "forms": {
      "Ïúº": true
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Link Google Drive Folders\n",
    "import os\n",
    "\n",
    "#@markdown --- \n",
    "#@markdown #### **1. Dataset Path**\n",
    "#@markdown Enter the path to your dataset folder in Google Drive (relative to 'My Drive').\n",
    "GOOGLE_DRIVE_DATASET_PATH = \"CoMoSVC_Dataset\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown --- \n",
    "#@markdown #### **2. Workspace Paths (Recommended)**\n",
    "#@markdown Enter folder names to save checkpoints and results in your Google Drive.\n",
    "GOOGLE_DRIVE_LOGS_PATH = \"CoMoSVC_Logs\" #@param {type:\"string\"}\n",
    "GOOGLE_DRIVE_RESULTS_PATH = \"CoMoSVC_Results\" #@param {type:\"string\"}\n",
    "\n",
    "# --- Link Dataset Folder --- \n",
    "full_drive_path = os.path.join(\"/content/drive/MyDrive\", GOOGLE_DRIVE_DATASET_PATH)\n",
    "local_path = \"dataset_raw\"\n",
    "\n",
    "if not os.path.exists(full_drive_path):\n",
    "    print(f\"‚ùå ERROR: The specified dataset path does not exist in your Google Drive: {full_drive_path}\")\n",
    "    print(\"Please create the folder and place your singer sub-folders inside it before proceeding.\")\n",
    "else:\n",
    "    if os.path.exists(local_path):\n",
    "        !rm -r {local_path}\n",
    "    !ln -s \"{full_drive_path}\" {local_path}\n",
    "    print(f\"‚úÖ Dataset folder linked successfully!\")\n",
    "    print(f\"   '{local_path}' -> '{full_drive_path}'\")\n",
    "\n",
    "# --- Link Checkpoints (Logs) Folder --- \n",
    "full_logs_path = os.path.join(\"/content/drive/MyDrive\", GOOGLE_DRIVE_LOGS_PATH)\n",
    "local_logs_path = \"logs\"\n",
    "!mkdir -p \"{full_logs_path}\"\n",
    "if os.path.exists(local_logs_path):\n",
    "    !rm -r {local_logs_path}\n",
    "!ln -s \"{full_logs_path}\" {local_logs_path}\n",
    "print(f\"‚úÖ Checkpoints (logs) folder linked successfully!\")\n",
    "print(f\"   '{local_logs_path}' -> '{full_logs_path}'\")\n",
    "\n",
    "# --- Link Results Folder --- \n",
    "full_results_path = os.path.join(\"/content/drive/MyDrive\", GOOGLE_DRIVE_RESULTS_PATH)\n",
    "local_results_path = \"results\"\n",
    "!mkdir -p \"{full_results_path}\"\n",
    "if os.path.exists(local_results_path):\n",
    "    !rm -r {local_results_path}\n",
    "!ln -s \"{full_results_path}\" {local_results_path}\n",
    "print(f\"‚úÖ Results folder linked successfully!\")\n",
    "print(f\"   '{local_results_path}' -> '{full_results_path}'\")\n",
    "\n",
    "!mkdir -p dataset # Create local dataset folder for preprocessed files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 4. Preprocessing\n",
    "\n",
    "This section processes the audio from your Google Drive folder (`dataset_raw`) and saves the features into the local Colab storage (`dataset`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 1: Resampling audio to 24000Hz mono...\")\n",
    "!python preprocessing1_resample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStep 2: Creating file lists and configuration...\")\n",
    "!python preprocessing2_flist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStep 3: Generating features...\")\n",
    "!python preprocessing3_feature.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Training\n",
    "\n",
    "This is the main training phase. It can take a **very long time** and requires a GPU. Thanks to our setup in Step 3, all model checkpoints will be saved directly to your Google Drive in the `CoMoSVC_Logs` folder (or whatever you named it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Train the Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Teacher Model training...\")\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Train the Consistency Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Consistency Model training...\")\n",
    "import os\n",
    "\n",
    "teacher_log_dir = \"logs/teacher\"\n",
    "teacher_model_path = \"\"\n",
    "try:\n",
    "    checkpoints = [f for f in os.listdir(teacher_log_dir) if f.endswith('.pt')]\n",
    "    if not checkpoints:\n",
    "        raise FileNotFoundError\n",
    "    latest_checkpoint = sorted(checkpoints)[-1]\n",
    "    teacher_model_path = os.path.join(teacher_log_dir, latest_checkpoint)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find any teacher model checkpoints in '{teacher_log_dir}'. Please train the teacher model first.\")\n",
    "\n",
    "if teacher_model_path:\n",
    "    print(f\"Using teacher model: {teacher_model_path}\")\n",
    "    config_path = \"configs/config.yaml\"\n",
    "    !python train.py -t -c \"{config_path}\" -p \"{teacher_model_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Inference\n",
    "\n",
    "Once training is complete, you can use your trained models to perform singing voice conversion. The final audio will be saved to your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Prepare Source Audio\n",
    "\n",
    "Upload the source audio file you want to convert to the `raw` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p raw\n",
    "\n",
    "print(\"Downloading a sample source audio file...\")\n",
    "!wget -O raw/source.wav https://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "!tar -xvzf raw/source.wav -C raw/ LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac > /dev/null 2>&1\n",
    "!ffmpeg -i raw/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac -ar 24000 raw/src.wav -y -hide_banner -loglevel error\n",
    "!rm -rf raw/LibriSpeech raw/source.wav\n",
    "\n",
    "print(\"Sample audio 'src.wav' is ready in the 'raw' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Run Inference\n",
    "\n",
    "Use the form below to configure the inference. You **must** set the `TARGET_SINGER` to the name of the folder you created in your Google Drive dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "forms": {
      "Ïúº": true
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Inference Configuration\n",
    "#@markdown --- \n",
    "#@markdown #### **Required Settings**\n",
    "TARGET_SINGER = \"my_singer\" #@param {type:\"string\"}\n",
    "#@markdown --- \n",
    "#@markdown #### **Inference Parameters**\n",
    "USE_CONSISTENCY_MODEL = True #@param {type:\"boolean\"}\n",
    "SOURCE_AUDIO = \"raw/src.wav\" #@param {type:\"string\"}\n",
    "PITCH_SHIFT = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
    "INFERENCE_STEPS = 5 #@param {type:\"slider\", min:1, max:50, step:1}\n",
    "\n",
    "import os\n",
    "\n",
    "if USE_CONSISTENCY_MODEL:\n",
    "    model_dir = \"logs/como\"\n",
    "    model_flag = \"-t\"\n",
    "    model_path_flag = \"-cm\"\n",
    "    config_path_flag = \"-cc\"\n",
    "    print(\"üé§ Using Consistency Model for inference.\")\n",
    "else:\n",
    "    model_dir = \"logs/teacher\"\n",
    "    model_flag = \"\"\n",
    "    model_path_flag = \"-tm\"\n",
    "    config_path_flag = \"-tc\"\n",
    "    print(\"üßë‚Äçüè´ Using Teacher Model for inference.\")\n",
    "\n",
    "try:\n",
    "    checkpoints = [f for f in os.listdir(model_dir) if f.endswith('.pt')]\n",
    "    if not checkpoints:\n",
    "        raise FileNotFoundError\n",
    "    latest_checkpoint = sorted(checkpoints)[-1]\n",
    "    model_path = os.path.join(model_dir, latest_checkpoint)\n",
    "    config_path = os.path.join(model_dir, \"config.yaml\")\n",
    "\n",
    "    print(f\"Found model: {model_path}\")\n",
    "\n",
    "    !python inference_main.py \\\n",
    "        -ts {INFERENCE_STEPS} \\\n",
    "        {model_path_flag} \"{model_path}\" \\\n",
    "        {config_path_flag} \"{config_path}\" \\\n",
    "        -n \"{SOURCE_AUDIO}\" \\\n",
    "        -k {PITCH_SHIFT} \\\n",
    "        -s \"{TARGET_SINGER}\" \\\n",
    "        {model_flag}\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n‚ùå ERROR: No models found in '{model_dir}'.\")\n",
    "    print(\"Please complete the training step (Section 5) before running inference.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during inference: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Listen to the Result\n",
    "\n",
    "The converted audio file is in your Google Drive (`CoMoSVC_Results` folder). The cell below will also display an audio player for the most recent result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "try:\n",
    "    list_of_files = glob.glob('results/*.wav')\n",
    "    if not list_of_files:\n",
    "        raise FileNotFoundError\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(f\"üé∂ Displaying result: {latest_file}\")\n",
    "    display(Audio(latest_file, rate=24000))\n",
    "except (ValueError, FileNotFoundError):\n",
    "    print(\"\\n‚ùå Could not find any output files in the 'results' directory.\")\n",
    "    print(\"Please ensure the inference step (Section 6) completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CoMoSVC_with_Google_Drive.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
